{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import viz tools\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Logger\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logger\n",
    "# Load config and logger\n",
    "from eztools.operations import Logger, ConfigReader\n",
    "logger = Logger('/mnt/logs/', logger_name = 'L&L').get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD_PATH = '/repos/my-awesome-project'\n",
    "\n",
    "# Change working directory\n",
    "os.chdir(CWD_PATH)\n",
    "sys.path.append(CWD_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from src.etl.get_data import read_csv_data\n",
    "from src.etl.get_missing_values import get_df_na, get_na_columns, impute_nan, plot_kdensity\n",
    "from src.etl.get_train_test_set import get_train_test_set\n",
    "from src.ml.get_lasso_model_predictions import get_lasso_model_predictions\n",
    "from src.ml.get_model_accuracy import get_model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config.ini\n",
    "CONFIG_PATH = '/repos/my-awesome-project/src/config/config.ini'\n",
    "config = ConfigReader(CONFIG_PATH, config_tuple = False).read_config()\n",
    "\n",
    "# Unpack config\n",
    "DATA_PATH = config['data']['data_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a function named **read_csv_data()** with the following properties:\n",
    "1. **Takes a full path for a file with a csv extension** <br>\n",
    "E.g. folder/subfolder/my_csv_data.csv\n",
    "2. **Output a dataframe with the correct rows and columns** <br>\n",
    "E.g. Indexes should not be presented as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = read_csv_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot info about the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Calculate missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a function named **get_df_na()** with the following properties: <br>\n",
    "1. **Contains two columns:** <br>\n",
    "number_of_nan & number_of_nan_prc\n",
    "2. **Captures the _absolute_ number of na values for a column name in the \"number_of_nan\" column** <br>\n",
    "E.g. \"pH\" column contains 4 na values in total\n",
    "3. **Captures the _percentage_ number of na values for a column name in the \"number_of_nan_prc\" column** <br>\n",
    "E.g. \"pH\" column contains 78% na values in total\n",
    "4. **Sort rows by descending order** <br>\n",
    "I.e. Columns with the highest number of na values will appear on the top rows in our newly create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get df with na values\n",
    "df_na = get_df_na(df)\n",
    "df_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a function named **get_na_columns()** witht the following properties: <br>\n",
    "1. **Gets a dataframe as an input where each row corresponds to a feature (i.e. column from a raw dataframe)** <br>\n",
    "E.g. the output of the get_df_na() function created above\n",
    "2. **Returns a list that holds all the row names that contain na values** <br>\n",
    "E.g. ['pH', 'density'] etc.\n",
    "3. **Makes the selection of which row name to keep according to a function argument named nan_column** <br>\n",
    "E.g. get_na_columns(df, nan_column = 'number_of_nan'), this means that the column 'number_of_nan' should be used for the row_name selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with nan values\n",
    "COLS_TO_IMPUTE = get_na_columns(df_na)\n",
    "COLS_TO_IMPUTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Impute nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of the missing columns\n",
    "plot_kdensity(df, 'pH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a function named **impute_nan()** with the following properties:\n",
    "1. **Gets a column or a list of columns to impute na values from with a specified replacement method (accept 'mean' & 'median')** <br>\n",
    "E.g. col = ['pH', 'density'] with replacement = 'median', means to do a median imputation for the 'pH' and 'density' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute nan values\n",
    "df = impute_nan(df, cols = 'pH', replacement = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Lasso Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a function named **get_train_test_set()** with the following properties:\n",
    "1. **Takes a dataframe as an input with a specifying response column to perform a 75%-25% split to train and test sets** <br>\n",
    "I.e. 75% for training and 25% for testing as per the default values of sklearn\n",
    "2. **Performs binary encoding for the response variable if specified** <br>\n",
    "E.g. if encode = True, then check which is the positive class specified by the <i>pos_class</i> function argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test_set(df, response = 'wine_colour', pos_class = 'white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a function named **get_lasso_model_predictions()** with the following properties:\n",
    "1. **Accepts a train dataset (X and y) to train a lasso model and performs predictions on unseen data (X test)** <br>\n",
    "E.g. X_train, X_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train lasso model and get predictions\n",
    "y_pred = get_lasso_model_predictions(X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a function named **get_model_accuracy()** with the following properties:\n",
    "1. **Accepts two pd.Series (1st: actual values, 2nd: expected/predicted values) and calculates the prediction accuracy** <br>\n",
    "E.g. 0.5 means 50% accuracy, 0.33 means 33% accuracy, 1 means 100 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "accuracy = get_model_accuracy(y_test, y_pred)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
